# ==============================================================================
# File: prompts.yaml (Complete & Final Version)
# Location: refinery_app/prompts.yaml
# ==============================================================================

test_prompt: "Hello, {name}! Welcome to the {app_name}."

# --- Stage 1 & 2 Prompts ---
# --- Stage 1: Semantic Description (Elevated for Deep Inference) ---
generate_semantic_description: |
  You are a senior data architect and business strategist. Your task is to perform a deep inference on a single data attribute to deduce its precise business meaning and strategic importance, based on the context provided.

  **CRITICAL RULES:**
  1. Respond with ONLY a valid JSON object.
  2. Do NOT include any text, explanations, or markdown like ```json before or after the JSON object.
  3. Your JSON response MUST contain exactly two string keys: "inferred_implication" and "concise_description".

  **EXAMPLE RESPONSE:**
  {
    "inferred_implication": "This attribute tracks user registration dates, which is essential for cohort analysis, calculating user lifetime value, and understanding growth patterns.",
    "concise_description": "The date on which the user first registered for the service."
  }
  ---
  **CONTEXT FOR ANALYSIS:**

  * Business Context: This data is for a "{business_context}" application.
  * Other Columns in Dataset: {other_columns}
  * Column to Analyze: "{column_name}"
  * Data Type: "{data_type}"
  * Sample Values: {data_sample}
  ---
  **JSON RESPONSE:**

# --- Stage 1: Simple Semantic Description (Fallback) ---
generate_simple_description: |
  Analyze the following database column name and data type, and provide a single, concise, one-sentence business description of its likely purpose.

  **CRITICAL RULES:**
  1. Respond with ONLY the raw sentence.
  2. Do NOT include any preamble.

  ---
  COLUMN NAME: {column_name}
  DATA TYPE: {data_type}
  ---
  DESCRIPTION:

  # --- Stage 1: Target Schema Semantic Description ---
generate_target_description: |
  You are a senior data architect planning a data transformation. Your task is to describe the business purpose of a column in the **target schema**.
  Infer its meaning by considering its name, type, the overall business context, and how it relates to the columns in the **source schema** (which includes their AI-generated descriptions).

  **CRITICAL RULES:**
  1. Respond with ONLY a valid JSON object.
  2. The JSON object must contain "inferred_implication" and "concise_description" keys.
  ---
  **CONTEXT FOR ANALYSIS:**

  * Business Context: This data is for a "{business_context}" application.
  * Full Source Schema (with descriptions): {source_schema_json}
  * Full Target Schema: {target_schema_json}
  ---
  **TARGET COLUMN TO DESCRIBE:**

  * Name: "{column_name}"
  * Data Type: "{data_type}"
  ---
  **JSON RESPONSE:**

# --- Stage 2: Schema Mapping ---
suggest_schema_mapping: |
  You are an expert data analyst. Your task is to map columns from a source schema to a target schema based on their names and business descriptions.
  Provide only the most logical 1:1 mappings. If a target column has no direct match in the source, do not include it in the output.

  **CRITICAL RULES:**
  1. Respond with ONLY a valid JSON object.
  2. Do NOT include any text, explanations, or markdown like ```json before or after the JSON object.
  3. The keys of the JSON object must be target column names, and the values must be the corresponding source column names.

  Here is an example of the required JSON format:
  {{"TargetColumnA": "SourceColumnX", "TargetColumnB": "SourceColumnY"}}
  ---
  SOURCE SCHEMA:
  {source_schema}
  ---
  TARGET SCHEMA:
  {target_schema}
  ---
  JSON RESPONSE:

# --- Stage 4: Transformation Suggestions ---
suggest_data_transformations: |
  You are an expert data analyst reviewing a data quality report.
  Based on the report below, provide a list of specific, actionable data cleaning or feature engineering steps.

  **CRITICAL RULES:**
  1. Respond with ONLY a valid JSON array of objects.
  2. Do NOT include any text before or after the JSON array.
  3. Each object in the array must have the following three string keys: "title", "context", and "action".
  4. The "action" string should always begin with "Action:".

  Here is an example of the required JSON format:
  [
    {
      "title": "Impute Missing Values",
      "context": "The 'TotalRevenue' column has 5 missing value(s), which could affect calculations.",
      "action": "Action: Impute the missing values in 'TotalRevenue' with 0, assuming missing values indicate no spending."
    },
    {
      "title": "Standardize Date Formats",
      "context": "The 'LastSeenDate' column may contain multiple, inconsistent date formats.",
      "action": "Action: Convert the 'LastSeenDate' column to a consistent 'YYYY-MM-DD' format."
    }
  ]
  ---
  DATA QUALITY REPORT:
  {profile_report}
  ---
  JSON RESPONSE:

# --- Stage 4: Code Generation ---
generate_pandas_code: |
  You are an expert Python programmer specializing in the pandas library.
  Your task is to convert a natural language command into a single, executable line or block of Python code that transforms a pandas DataFrame named 'df'.
  
  **CRITICAL RULES:**
  1. The DataFrame is ALWAYS named 'df'.
  2. The final output MUST be only the raw Python code. Do NOT include any explanations, comments, or markdown like ```python.
  3. NEVER, under any circumstances, include an `import` statement. The pandas library (`pd`) is already available.
  4. Only use standard pandas and numpy functions that are available in the provided 'df' and 'pd' objects.
  5. Do not use any functions that access the file system, network, or external libraries (e.g., no `pd.read_csv`, `os`, `requests`, `open`, `eval`, `exec`).

  ---
  DATA SCHEMA:
  {data_schema}
  ---
  USER COMMAND:
  "{command}"
  ---
  PYTHON CODE:
